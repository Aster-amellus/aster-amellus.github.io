[{"title":"Introduction to zk-SNARKs","url":"/2025/05/21/Introduction-to-zk-SNARKs/","content":"Part1 初识 zk-SNARKs\n在深入探讨 zk-SNARKs 的复杂机制之前，我们首先需要理解其核心概念——零知识证明，并弄清楚 zk-SNARK 这个缩写词中每个字母所代表的含义。\n1.1 零知识证明 (ZKP) 到底是什么？\n零知识证明 (Zero-Knowledge Proof, ZKP) 是一种神奇的密码学协议。它的核心思想是：证明者 (Prover) 能够向 验证者 (Verifier) 证明她知道某个秘密（例如一个问题的答案，或者一个数学难题的解），或者某个论断为真，但在这个过程中，验证者除了确信“该论断为真”这一事实之外，不会获得任何关于这个秘密或论断的具体信息 。\n想象一下，证明者想要证明她知道一个宝箱的密码，但又不想把密码告诉验证者。零知识证明就能让她在不泄露密码本身的情况下，让验证者相信她确实知道密码。\n一个有效的零知识证明系统必须满足三个核心属性 ：\n\n完整性 (Completeness): 如果证明者确实知道秘密（即声明为真），并且证明者和验证者都诚实地遵循协议，那么验证者最终一定会被说服。换句话说，真实的证明总能通过验证。Interactive zero knowledge 3-colorability demonstration\n可靠性 (Soundness): 如果证明者并不知道秘密（即声明为假），那么她几乎不可能欺骗诚实的验证者，让验证者相信声明为真 。即使证明者试图作弊，她成功欺骗验证者的概率也应该极小，可以忽略不计 。\n零知识性 (Zero-Knowledge): 这是 ZKP 最核心也是最反直觉的特性。验证者在与证明者交互（或接收证明）之后，除了知道“声明为真”这一结论外，不会获得任何额外的信息。严格来说，这意味着验证者自己可以“模拟”出一个与真实证明者交互的副本，而这个模拟过程不需要证明者的任何秘密输入 。如果验证者能自己模拟出交互过程，那么真实的交互过程自然也没有泄露任何额外信息。\n\n以下是来自zk-SNARKs: A Gentle Introduction的一个零知识证明 的例子:\n\nImagine that we pick a card A♦ from a complete deck of playing cards and we\nwant to prove to an adversary that we have a red card in our hand. We can prove that by revealing more\ninformation than expressed in the statement, just by showing our card, say it was an ace of diamonds A♦.\nAlternatively, we can choose to prove nothing more than the colour of our card by revealing to the adversary\nall the black cards ♣, ♠ left in the deck. Our opponent should now be convinced we have a red card in our\nhands, but it did not learn anything else about the value of our card.\n\n零知识证明的核心思想便是证明者可以在不泄露任何额外信息的前提下，令验证者信服某个声明的真实性。这种能力彻底改变了我们对数字世界中信任和验证的认知，从依赖身份或完全公开信息，转变为依赖特定声明的数学证明。\n1.2 ZKP系统及分类\nZKP 系统可以根据其交互模式、证明大小、验证时间、设置要求和底层密码学假设等多个维度进行分类。\n\n\n交互式与非交互式证明：\n\n\n交互式 ZKPs (Interactive ZKPs) 需要证明者和验证者之间进行多轮通信 。\n\n\n非交互式 ZKPs (Non-Interactive ZKPs, NIZKs) 仅需证明者向验证者发送单条消息。它们通常依赖于一个公共参考串 (Common Reference String, CRS) 或 Fiat-Shamir 启发式方法来消除交互 。NIZKs 对于像区块链这样的去中心化系统尤其有用，因为在这些系统中，各方可能无法同时在线 。  \nzk-SNARKs (Zero-Knowledge Succinct Non-Interactive Argument of Knowledge)：\n\n主要特点是简洁的 (succinct) 证明（即证明的尺寸很小）和快速的验证时间，且验证时间与原始计算的复杂度无关 。  \n许多早期和流行的 zk-SNARKs（例如 Groth16）需要针对每个电路进行一次可信设置 (trusted setup)。在此过程中会生成一些秘密参数（有时被称为“有毒废料”toxic waste）。如果这些秘密参数被泄露，整个证明系统的安全性将受到破坏 。  \n较新的 SNARKs，如 PLONK，提供了通用的 (universal) 和可更新的 (updatable) 可信设置 。\nzk-SNARKs 通常依赖于椭圆曲线密码学 (Elliptic Curve Cryptography, ECC) 和配对 (pairings) 。\n\n\n\nzk-STARKs (Zero-Knowledge Scalable Transparent Argument of Knowledge)：\n\n\n透明性 (Transparent)：\n\n\n不需要可信设置；它们使用公开的随机性和哈希函数来代替 。  \n可扩展性 (Scalable)： 专为大规模计算设计，尽管其证明尺寸通常比 SNARKs 更大 。\n\n\n后量子安全性 (Plausible Post-Quantum Security)： 依赖于哈希函数，这使得它们被认为具有潜在的抗量子攻击能力 。\n \n-Bulletproofs：\n\n提供无需可信设置的简短证明，特别适用于证明某个值位于特定范围内 。  \n其证明尺寸相对于电路的门数量是对数级的 。Bulletproofs 已被应用于 Monero 等加密货币中 。  \n-设置的角色：可信设置 vs. 透明设置：\n\n\n\n可信设置： 此过程涉及生成一组参数（CRS 或结构化参考串 SRS），这些参数的生成依赖于一个必须被安全销毁的秘密（“有毒废料”）。如果该秘密被泄露，攻击者就可以伪造无效的证明 。多方计算 (Multi-Party Computation, MPC) 仪式旨在通过分散信任来降低风险，即只要有一个参与方是诚实的并销毁了其随机性份额，组合的秘密就无法被重构 。例如 Groth16 和许多早期的 zk-SNARKs。\n\n\n透明设置： 不依赖于秘密参数，通常使用公开的随机性和哈希函数 。例如 STARKs、Bulletproofs、一些较新的 SNARKs（如 Halo2）以及基础的 GKR 协议。\n\n\n\n\n\n\nZKP领域正从特定可信设置系统向透明系统（如STARKs、Bulletproofs）或通用/可更新设置系统（如PLONK）演进，主要因为可信设置存在安全风险和部署复杂性。这种转变提高了系统的健壮性和易用性。\n各类ZKP系统在证明大小、计算时间、设置要求和密码学假设间有不同权衡：\n\nzk-SNARKs: 极小的证明和快速验证，但需可信设置，非量子安全\nzk-STARKs: 透明且量子安全，但证明较大\nBulletproofs: 透明系统，主要用于范围证明\nGKR: 基础形式透明但交互式，未优化时可能较慢\n\nFiat-Shamir启发式方法是将交互式证明转为非交互式的重要技术，通过哈希函数替代验证者随机性，使得ZKP能适用于区块链等无法实时交互的场景。\n零知识保证强度也有差异（计算性、统计性、完美性）。实际应用通常采用计算性零知识，这对大多数场景已足够安全，而完美零知识虽然保证更强，但实现更难且效率更低。\n\n\n\nZKP 类型\n可信设置\n典型证明大小\n典型验证复杂度\n典型证明复杂度\n后量子安全 (可能)\n关键密码学原语\n\n\n\n\nzk-SNARK (类 Groth16)\n是 (每个电路)\n常数\n常数\nO(NlogN)O(NlogN)O(NlogN) 或更高\n否\n配对、ECC、QAP/R1CS\n\n\nzk-SNARK (类 PLONK)\n是 (通用/可更新)\n对数或多对数\n对数或多对数\nO(NlogN)O(NlogN)O(NlogN)\n否\n配对、ECC、多项式承诺 (如 KZG)\n\n\nzk-STARK\n否 (透明)\n多对数\n多对数\n准线性\n是\n哈希函数、FRI\n\n\nBulletproofs\n否 (透明)\n对数\n线性\n线性\n否\nECC、内积论证\n\n\nGKR (基础交互式)\n否 (透明)\n多对数 (依赖深度)\n多对数 (依赖深度)\n(准)线性\n取决于组件和校验\n多线性扩展\n\n\nGKR (非交互式 ZK)\n取决于 PCS\n多对数 (依赖深度)\n多对数 (依赖深度)\n(准)线性\n取决于组件和校验、MLE、PCS、Fiat-Shamir\n\n\n\n\n1.3 zk-S N A R Ks\n理解了零知识证明的基本概念后，我们再来看 zk-SNARK 这个具体的零知识证明技术。它的全称是 “Zero-Knowledge Succinct Non-interactive ARgument of Knowledge” 。每一个字母都代表着一项至关重要的特性，这些特性共同造就了 zk-SNARKs 的强大威力与实用性。\n\n\n\n字母\n英文\n中文\n解释\n\n\n\n\nZK\nZero-Knowledge\n零知识\n证明者在不泄露任何秘密信息的前提下，让验证者相信某个论断为真。\n\n\nS\nSuccinct\n简洁\n证明的体积很小，验证过程非常快速，通常与原始计算的复杂度无关。\n\n\nN\nNon-interactive\n非交互\n证明者和验证者之间仅需一次单向通信（证明者发送证明给验证者），无需来回交互。\n\n\nAR\nArgument (of)\n论证\n表明其可靠性基于计算假设（例如，证明者算力有限，无法攻破底层的密码学难题），而非绝对的数学定理意义上的“证明”。\n\n\nK\nKnowledge\n知识\n证明者确实“拥有”其声称拥有的特定知识（即“证据”或“见证”，英文称为 witness）。\n\n\n\n为什么需要zk-SNARKs\n\n\n隐私保护，这点无需多言\n\n\n可拓展性（针对区块链）\n\n以区块链为例，传统公链（如以太坊）的所有交易都需要在主链上逐一处理和验证，这导致了网络拥堵、交易速度慢和手续费高昂的问题，即“可扩展性困境”。zk-SNARKs通过“简洁性”解决了这个问题。 它可以将大量复杂的计算或交易聚合起来，生成一个非常小且易于验证的“证明”。验证者只需验证这个小小的证明，就能确认所有聚合的交易或计算的正确性，而无需重新执行所有原始操作。这使得zk-Rollups等Layer 2扩容方案成为可能，极大地提高了区块链的吞吐量和效率，降低了用户成本，从而让区块链技术能够支持更广泛、更大规模的应用。\n\n\n\n隐私保护的机器学习\n\n可以证明一个机器学习模型对某个输入给出了特定的输出，或者模型本身满足某些属性，而无需暴露模型的内部参数或训练数据。\n\n\n\nPart2 稍微更深入的介绍zk-SNARKs\n2.1 NARK: Non-interactive ARgument of Knowledge\nNARK系统围绕一个核心的数学问题展开，这个数学问题可以用一个公共算术电路 (Public arithmetic circuit) C(x,w)C(x,w)C(x,w) 来表示。\n\nxxx (公共陈述 Public Statement)：这是大家都知道的公开信息，比如一个计算难题的题目。\nwww (秘密证据 Secret Witness)：这是只有“证明者”才知道的秘密信息，比如那个难题的答案。\n目标：证明者想让“验证者”相信，他确实拥有一个 www，使得 C(x,w)=0C(x,w)=0C(x,w)=0 成立（即，他的答案 www 对于题目 xxx 是正确的），并且在这个过程中，不泄露 www 本身。\n\n\n第一步：预处理/设置 (Preprocessing/Setup)\n\n在任何证明开始之前，系统会根据要证明的电路 CCC 生成两套公共参数：\n\npppppp (Proving Parameters, 证明参数)：提供给证明者。\nvpvpvp (Verification Parameters, 验证参数)：提供给验证者。\n\n该步骤针对固定电路 CCC 只需执行一次，之后可反复使用。\n\n第二步：生成证明 (Proving)\n\n证明者持有以下输入：\n\n证明参数 pppppp\n公共陈述 xxx\n秘密见证 www\n\n利用这些，证明者生成一个证明 π\\piπ，使得 C(x,w)=0C(x,w)=0C(x,w)=0 的成立性被“简短地”编码在 π\\piπ 中。\n\n第三步：验证 (Verification)\n\n验证者收到来自证明者的 π\\piπ 以及公开的 xxx，并使用：\n\n验证参数 vpvpvp\n公共陈述 xxx\n证明 π\\piπ\n\n进行检验。如果验证通过，则接受 (accept) 并相信存在某个秘密 www 使 C(x,w)=0C(x,w)=0C(x,w)=0；否则拒绝 (reject)。\nNARK的“N”代表“非交互式”。这意味着整个证明过程非常简洁：证明者只需发送一条消息（即证明 π\\piπ）给验证者，验证者就可以独立完成验证，不需要来回的多轮对话。\n2.2 SNARK: Succinct NARKs\n如果说NARKs让我们能够“证明我知道，但不泄密”，那么SNARKs则是在此基础上，让这个过程变得极其高效。SNARK中的“S”代表Succinct（简洁的），这正是它的核心特性。\n在预处理阶段，和 NARKs 一样，我们同样可以去定义一个三元组 (S,P,V)(S,P,V)(S,P,V)（即初始的设置算法 S(C)S(C)S(C)，证明者 Prover，验证者 Verifier）。与上面不同的是，这里 Prover 提供的证明 π\\piπ 是一个 “short proof”，它的长度仅与原始电路规模 ∣C∣|C|∣C∣ 的对数多项式（polylog⁡(∣C∣)\\operatorname{polylog}(|C|)polylog(∣C∣)）成正比。Verifier 拿到这个 “迷你” 证明 π\\piπ、公开信息 xxx 以及那个 “简短总结” 的验证参数 vpvpvp 后，同样可在对数多项式时间内进行验证。\n总结一下，SNARKs继承了NARKs“证明知识而不泄露知识”的特性，并通过引入“简洁性”，使得证明本身变得极小，验证过程极其迅速。这使得对非常复杂的计算进行可信公开验证成为可能，而无需让验证者重复整个计算或处理庞大的证明数据。\nPart3 解构SNARKs：从PCP理论到SNARKs\n我们已经知道SNARKs（简洁非交互式知识论证）拥有证明小、验证快的核心特点。基于PCP定理,我们有一种构建SNARK的“简单”方法。虽然“简单”是相对理论而言，实际细节可能颇为复杂，但其核心思想非常精彩。\n3.1 PCP定理（Probabilistically Checkable Proofs Theorem）\nPCP定理 (The PCP theorem)的核心思想是对于任何一个计算问题（可以用算术电路 C(x,w)C(x,w)C(x,w) 表示，其中 xxx 是公开输入，www 是秘密证据），都存在一个证明系统，使得：\n\n证明者 (Prover) P(pp,x,w)P(pp,x,w)P(pp,x,w) 生成一个（可能很长的）证明 πππ。\n验证者 (Verifier) 只需要随机读取这个证明 π 中的极少数几位（比如 O(λ)O(λ)O(λ) 位，其中 λλλ 是安全参数），就能以极高的概率判断证明是否有效。\n\n如果存在一个合法的 www 使得 C(x,w)=0C(x,w)=0C(x,w)=0，验证者总是接受有效的证明。\n如果不存在这样的 www，验证者将以极高的概率拒绝无效的证明。\n\n关键问题：PCP定理本身虽然强大，但它生成的原始证明 πππ 的大小通常是电路规模 ∣C∣∣C∣∣C∣ 的多项式级别，即 size of proof π\\piπ is poly(|C|)。这并不简洁 (not succinct)，所以它还不是SNARK。\n\n3.2 “SNARK化”PCP证明（但仍是交互式）\nPCP验证者只需读取证明的少数几位，但它需要能够访问整个（可能很长的）证明。如何让验证者在不实际接收整个长证明的情况下，确信这几位的内容呢？答案是Merkle Tree。\n步骤如下：\n证明者 P(pp,x,w)P(pp,x,w)P(pp,x,w)：\n首先，像往常一样生成完整的PCP证明 πππ。\n然后，将这个长证明 πππ 的所有数据块作为叶子节点，构建一棵Merkle Tree。\n证明者只发送这棵树的Merkle root hhh (一个哈希值) 给验证者。这个根 hhh 非常短。\n验证者 V(vp,x,h)V(vp,x,h)V(vp,x,h)：\n验证者（根据PCP协议）决定它需要检查PCP证明 πππ 中的哪 kkk 个位置（比如 k=O(λ)k=O(λ)k=O(λ) 个位置）。\n它向证明者请求这 kkk 个位置的数据以及它们对应的Merkle路径（用于验证这些数据确实属于由根 h 代表的那棵树）。\n证明者：回应这 kkk 个位置的数据和它们的Merkle路径。\n验证者：\n使用Merkle路径验证这 kkk 个数据块的真实性和完整性（即它们确实来自以 hhh 为根的树）。\n对这 kkk 个（已验证的）数据块执行原始的PCP验证逻辑。\n输出接受或拒绝。\n成果：\n验证者实际接收的数据量是 kkk 个数据块加上 kkk 条 Merkle 路径。每条 Merkle 路径的长度大约是 log⁡∣π∣\\log |\\pi|log∣π∣ 或者说 log⁡(poly⁡(∣C∣))\\log(\\operatorname{poly}(|C|))log(poly(∣C∣))，也就是 O(log⁡∣C∣)O(\\log |C|)O(log∣C∣)。所以总数据量是 O(k log⁡∣C∣)O(k\\,\\log |C|)O(klog∣C∣)，即 O(λ log⁡∣C∣)O(\\lambda\\,\\log |C|)O(λlog∣C∣)。这已经非常简洁（succinct proof）了。\n但还是遗留了一个问题：这个过程是交互式的 (interactive)。验证者需要先向证明者“索要”特定位置的数据。SNARK要求非交互性。\n3.3 直面恐惧 斩断循环 Fiat-Shamir变换登场\n为了消除交互，密码学提供了一个强大的工具：Fiat-Shamir变换 (The Fiat-Shamir transform)。\n核心思想：它可以将一个“公开掷币”(public-coin)的交互式协议转换为非交互式协议。在公开掷币协议中，验证者的消息仅仅是随机数。Fiat-Shamir的思想是，让证明者自己通过一个密码学哈希函数（通常被建模为随机预言机）来生成这些“随机数”。\n这可以应用到我们的场景，在交互式版本中，验证者需要选择 kkk 个“随机”位置来查询。\n让我们来进行非交互式改造：\n\n\n证明者 P(pp,x,w)P(pp,x,w)P(pp,x,w)：\n\n\n生成 PCP 证明 π\\piπ，构建 Merkle Tree，得到 Merkle root hhh（这可以看作是交互协议的第一条消息 msg1\\mathrm{msg}_1msg1​）。证明者不等待验证者，而是自己计算一个哈希值，例如 H(Merkle root h,x)H(\\text{Merkle root } h, x)H(Merkle root h,x)（哈希函数的输入通常包含当前对话的所有公开信息，以确保挑战的不可预测性）。这个哈希函数的输出被用来确定那 kkk 个要查询的位置。\n\n证明者“打开”这 kkk 个由哈希值决定的位置，准备好对应的数据和 Merkle 路径（这构成了第二部分消息 msg2\\mathrm{msg}_2msg2​）。\n\n\n\n最终的非交互式证明 π′\\pi&#x27;π′ 就是 Merkle Tree root 的哈希值 hhh，以及根据 H(h,x)H(h, x)H(h,x)（哈希函数作用于根哈希值 hhh 和公开输入 xxx）计算出的 kkk 个位置所对应的被揭示数据及其 Merkle Path。其大小依然是 O(λ log⁡∣C∣)O(\\lambda\\, \\log |C|)O(λlog∣C∣)。\n\n\n验证者 V(vp,x,π′)V(vp,x,\\pi&#x27;)V(vp,x,π′)：\n\n收到证明 π′=(h,openings)\\pi&#x27;=(h,\\text{openings})π′=(h,openings)。（“Openings” 指的是实际的数据值，即从原始 PCP 证明中挑选出来的 kkk 个特定位置的数据块本身。）\n\n\n\n使用相同的哈希函数 H(h,x)H(h, x)H(h,x) 来独立地重新计算出那 kkk 个应该被查询的位置。\n\n检查证明中提供的“openings”是否与自己计算出的位置相符，并验证Merkle路径的正确性。\n对数据执行原始PCP验证。\n\n\n\n通过Fiat-Shamir变换，我们得到了一个非交互式的 (non-interactive) 并且证明依然是简洁的 (succinct) 协议。\n3.4 我们成功了吗？—— “透明”SNARK的代价\n至此，我们似乎通过PCP理论和Fiat-Shamir变换构建了一个“简单且透明的SNARK”（透明指的是它不需要像某些SNARKs那样依赖可信设置）。\n好消息：理论上可行，思路清晰。\n坏消息：an impractical SNARK — Prover time too high。\n这个方案的主要瓶颈是生成原始的 PCP（PCP of computation，即对计算本身的 PCP 证明）或者完整的 PCP 证明 π\\piπ 本身，对于证明者来说计算开销极大。PCP 的构造通常涉及复杂的编码和代数技术，导致证明者的计算时间远超实际应用的承受范围。\n虽然上述基于PCP的直接构造在实践中证明者开销过大，但它为理解SNARKs的构成提供了宝贵的视角。\nBetter SNARKs: Goal: Time(Prover)=O~(∣C∣)\\mathrm{Time}(\\text{Prover}) = \\tilde{O}(|C|)Time(Prover)=O~(∣C∣)。\n理想的 SNARK 应该让证明者的计算时间尽可能接近电路规模 ∣C∣|C|∣C∣ 的线性级别 O~(∣C∣)\\tilde{O}(|C|)O~(∣C∣)（通常忽略对数因子）。现代很多实用的 SNARK 方案（如 Groth16、PLONK、Marlin 等）正是通过更精巧的代数和密码学技术（如多项式承诺、双线性配对等）来努力实现或逼近这个目标的，它们通常不直接依赖于上述这种“经典” PCP 构造。\nPart4 zk-SNARKs的基本思想及步骤\n4.1 从计算问题到多项式\nzk-SNARKs 的核心思想之一，是将任何我们想要证明的计算问题（例如，一个程序是否正确执行，一个函数的输出是否为某个特定值）转换成一个关于多项式的等式。如果证明者能够展示他知道如何满足这个多项式等式，就等同于他知道原始计算问题的解（即“见证” witness）。这个转换过程是实现零知识证明的关键步骤，通常可以概括为以下几个阶段 ：\n计算问题 → 算术电路 → R1CS → QAP → 多项式证明\n\n\n\n阶段 (Stage)\n输入 (Input)\n输出 (Output)\n核心思想 (Key Idea)\n\n\n\n\n1. 计算叙述 (Computation)\n待证明的计算逻辑 (e.g., a programf(w)=vf(w)=vf(w)=v)\n程序代码 (Program Code)\n定义要证明的计算任务。\n\n\n2. 扁平化 (Flattening)\n程序代码 (Program Code)\n算术电路 (Arithmetic Circuit) / 一系列简单算术门 (e.g.,x=y∗z,x=y+ze.g., x = y * z, x = y + ze.g.,x=y∗z,x=y+z)\n将复杂计算分解为基本的加法和乘法门。\n\n\n3. R1CS 转换\n算术电路 (Arithmetic Circuit)\n一组一阶约束 (Rank-1 Constraints) s.A∗s.B−s.C=0s.A * s.B - s.C = 0s.A∗s.B−s.C=0\n将每个算术门表示为一个向量约束，s 是包含所有变量的见证 (witness)。\n\n\n4. QAP 转换\nR1CS 约束组\n一组多项式 Aj(x),Bj(x),Cj(x)A_j(x), B_j(x), C_j(x)Aj​(x),Bj​(x),Cj​(x) 和目标多项式 Z(x)Z(x)Z(x)\n将 R1CS 约束转换为一个多项式整除问题: ∑jsjAj(x)⋅∑jsjBj(x)−∑jsjCj(x)=H(x)Z(x)\\sum_{j}s_jA_j(x) \\cdot \\sum_{j}s_jB_j(x) - \\sum_{j}s_jC_j(x) = H(x)Z(x)∑j​sj​Aj​(x)⋅∑j​sj​Bj​(x)−∑j​sj​Cj​(x)=H(x)Z(x)。通常使用拉格朗日插值等技术。\n\n\n\n4.2 核心加密工具\n将计算问题转化为多项式等式后，我们需要一套加密工具来让证明者在不泄露见证 sss 和商多项式 H(x)H(x)H(x) 的情况下，向验证者证明这个等式的成立。以下是 zk-SNARKs (特别是基于 QAP 的方案如 Groth16) 中常用的一些核心加密工具：\n同态隐藏 (Homomorphic Hiding - HH)\n同态隐藏是一种特殊的加密函数，我们称之为 E(v)E(v)E(v)，它能够隐藏输入值 vvv 的具体内容，但同时允许对加密后的值（即隐藏值）进行某些特定的代数运算。运算的结果，如果解密（或解除隐藏），将等同于先对原始值进行相同的运算，然后再对运算结果进行加密。\n例如，一个加法同态隐藏方案满足 E(v1)⊕E(v2)=E(v1+v2)E(v_1) \\oplus E(v_2) = E(v_1 + v_2)E(v1​)⊕E(v2​)=E(v1​+v2​)，其中 ⊕\\oplus⊕ 是对隐藏值的某种运算。更进一步，如果它支持标量乘法，即能从 E(v)E(v)E(v) 计算出 E(c⋅v)E(c \\cdot v)E(c⋅v)（对于已知的常数 ccc），那么它就支持线性组合的同态性：从 E(v1)E(v_1)E(v1​) 和 E(v2)E(v_2)E(v2​) 可以计算出 E(c1v1+c2v2)E(c_1 v_1 + c_2 v_2)E(c1​v1​+c2​v2​)。\n一个常见的例子是基于离散对数难题的指数形式：令 E(v)=gv mod pE(v) = g^v \\bmod pE(v)=gvmodp，其中 ggg 是一个生成元，ppp 是一个大素数。那么：\nE(v1)⋅E(v2)=gv1⋅gv2=gv1+v2=E(v1+v2)E(v_1) \\cdot E(v_2) = g^{v_1} \\cdot g^{v_2} = g^{v_1 + v_2} = E(v_1 + v_2)\nE(v1​)⋅E(v2​)=gv1​⋅gv2​=gv1​+v2​=E(v1​+v2​)\n这里，对隐藏值的乘法对应于对原始值的加法。\n在 zk-SNARKs 中的作用： 同态隐藏使得证明者可以在不泄露秘密见证 sks_ksk​ 的情况下，计算 QAP 中组合多项式 L(x),R(x),O(x)L(x), R(x), O(x)L(x),R(x),O(x) 在某个秘密点 τ\\tauτ (通常由可信设置提供，证明者也不知道其具体值) 的“隐藏值”。例如，验证者提供 τ\\tauτ 的幂次的隐藏值 E(τ0),E(τ1),…,E(τd)E(\\tau^0), E(\\tau^1), \\dots, E(\\tau^d)E(τ0),E(τ1),…,E(τd)。证明者知道多项式 Ak(x)A_k(x)Ak​(x) 的系数（这些系数是公开的）和秘密见证 sks_ksk​，他可以利用同态性计算出 E(L(τ))=E(∑skAk(τ))E(L(\\tau)) = E(\\sum s_k A_k(\\tau))E(L(τ))=E(∑sk​Ak​(τ))，而验证者无法从中反推出 sks_ksk​ 或 τ\\tauτ。\n多项式承诺方案 (Polynomial Commitment Schemes - PCS)\n多项式承诺方案允许证明者对一个多项式 P(x)P(x)P(x) 进行“承诺”(Commit)，生成一个简短的承诺值 CCC。这个承诺值就像对该多项式的一个加密摘要。稍后，证明者可以“打开”(Open)这个承诺，并证明 P(x)P(x)P(x) 在某个特定点 zzz 的取值为 vvv（即 P(z)=vP(z)=vP(z)=v），而这个证明过程同样不需要揭示整个多项式 P(x)P(x)P(x) 的所有系数。KZG (Kate-Zaverucha-Goldberg) 承诺 是一种非常流行且高效的多项式承诺方案，它依赖于双线性配对和一次性的可信设置。\n\n可信设置: 生成公共参数，包括椭圆曲线群 G1,G2G_1, G_2G1​,G2​ 的生成元 g1,g2g_1, g_2g1​,g2​ 以及一个秘密值 τ\\tauτ 的幂次在群上的表示：{g1,τg1,τ2g1,…,τdg1}\\{g_1, \\tau g_1, \\tau^2 g_1, \\dots, \\tau^d g_1\\}{g1​,τg1​,τ2g1​,…,τdg1​} 和 {τg2}\\{\\tau g_2\\}{τg2​}。这个秘密 τ\\tauτ 就是“有毒废料”，设置完成后必须销毁。\n承诺阶段: 证明者有一个 ddd 次多项式 P(x)=∑i=0dcixiP(x) = \\sum_{i=0}^d c_i x^iP(x)=∑i=0d​ci​xi。他使用可信设置提供的参数计算承诺 C=P(τ)⋅g1=(∑i=0dciτi)⋅g1=∑i=0dci(τig1)C = P(\\tau) \\cdot g_1 = (\\sum_{i=0}^d c_i \\tau^i) \\cdot g_1 = \\sum_{i=0}^d c_i (\\tau^i g_1)C=P(τ)⋅g1​=(∑i=0d​ci​τi)⋅g1​=∑i=0d​ci​(τig1​)。注意，证明者是在指数上进行计算，他并不知道 τ\\tauτ 的值。\n证明求值 (Opening): 证明者想证明 P(z)=vP(z)=vP(z)=v。他构造一个商多项式 Q(x)=P(x)−vx−zQ(x) = \\frac{P(x)-v}{x-z}Q(x)=x−zP(x)−v​。如果 P(z)=vP(z)=vP(z)=v 成立，那么 (x−z)(x-z)(x−z) 必然是 P(x)−vP(x)-vP(x)−v 的一个因子，所以 Q(x)Q(x)Q(x) 是一个真正的多项式。证明者计算并发送证据 w=Q(τ)⋅g1w = Q(\\tau) \\cdot g_1w=Q(τ)⋅g1​。\n验证阶段: 验证者收到承诺 CCC、点 (z,v)(z,v)(z,v) 和证据 www。他使用双线性配对来检查一个等式是否成立，该等式本质上是在验证 P(τ)−v=Q(τ)(τ−z)P(\\tau)-v = Q(\\tau)(\\tau-z)P(τ)−v=Q(τ)(τ−z) 在指数上是否成立。一个常见的验证方程是 e(C−v⋅g1,g2)=e(w,τg2−z⋅g2)e(C - v \\cdot g_1, g_2) = e(w, \\tau g_2 - z \\cdot g_2)e(C−v⋅g1​,g2​)=e(w,τg2​−z⋅g2​)。如果等式成立，验证者就相信 P(z)=vP(z)=vP(z)=v。\n\n在 zk-SNARKs 中的作用: PCS 用于让证明者承诺其构造的 QAP 多项式（如 L(x),R(x),O(x)L(x), R(x), O(x)L(x),R(x),O(x) 或 P(x),H(x)P(x), H(x)P(x),H(x)），并在一个由验证者（或协议本身通过密码学方式）选择的随机挑战点（通常就是可信设置中的秘密 τ\\tauτ）上证明这些多项式满足 QAP 所要求的等式 P(τ)=H(τ)Z(τ)P(\\tau) = H(\\tau)Z(\\tau)P(τ)=H(τ)Z(τ)，而无需发送这些可能非常大的多项式的全部系数。\n椭圆曲线对 (Elliptic Curve Pairings)\n椭圆曲线对（或称双线性映射）是一种特殊的数学工具，它在现代密码学中扮演着越来越重要的角色，尤其是在 zk-SNARKs 的构造中。\n一个双线性配对 eee 是一个映射，它取自两个（可能相同的）椭圆曲线点群 G1G_1G1​ 和 G2G_2G2​ 的元素，并将它们映射到第三个（通常是乘法）群 GTG_TGT​ 中的一个元素：e:G1×G2→GTe: G_1 \\times G_2 \\to G_Te:G1​×G2​→GT​。\n它必须满足以下关键性质：\n\n双线性 (Bilinearity): 对于任意的点 P∈G1,Q∈G2P \\in G_1, Q \\in G_2P∈G1​,Q∈G2​ 和任意的标量 a,ba,ba,b，有 e(aP,bQ)=e(P,Q)abe(aP, bQ) = e(P,Q)^{ab}e(aP,bQ)=e(P,Q)ab。这意味着我们可以将标量乘法从配对的一个输入参数“移动”到另一个输入参数，或者“提取”到指数上。\n非退化性 (Non-degeneracy): 如果 g1,g2g_1, g_2g1​,g2​ 分别是 G1,G2G_1, G_2G1​,G2​ 的生成元，那么 e(g1,g2)≠1GTe(g_1, g_2) \\neq 1_{G_T}e(g1​,g2​)=1GT​​ (其中 1GT1_{G_T}1GT​​ 是 GTG_TGT​ 的单位元)。这确保了配对不是一个平凡的映射。\n\n在 zk-SNARKs 中的作用: 双线性配对是许多 zk-SNARKs 方案（特别是那些基于 QAP 和 KZG 承诺的方案，如 Groth16）实现简洁验证和非交互性的核心机制。它们允许在“加密”空间（即椭圆曲线点，它们隐藏了底层的标量值）中有效地验证乘法关系。例如，上面提到的 KZG 承诺的验证方程 e(C−v⋅g1,g2)=e(w,τg2−z⋅g2)e(C - v \\cdot g_1, g_2) = e(w, \\tau g_2 - z \\cdot g_2)e(C−v⋅g1​,g2​)=e(w,τg2​−z⋅g2​) 就是一个典型的应用。这个方程通过配对，巧妙地验证了原始多项式 P(x)P(x)P(x) 在点 zzz 的取值为 vvv，而验证者既不需要知道多项式 P(x)P(x)P(x) 本身，也不需要知道秘密值 τ\\tauτ。配对使得我们可以在不知道具体数值的情况下，检查它们之间是否存在预期的代数关系，这对于验证 QAP 方程 P(τ)=H(τ)Z(τ)P(\\tau) = H(\\tau)Z(\\tau)P(τ)=H(τ)Z(τ) 至关重要。\n这三种加密工具——同态隐藏、多项式承诺和椭圆曲线对——并非孤立存在，它们在 zk-SNARK 的构造中协同工作。同态隐藏使得证明者可以在秘密值上进行计算；多项式承诺方案使得证明者可以对这些计算的结果（即多项式）进行简洁的承诺，并证明其在特定点上的取值；而椭圆曲线对则提供了在隐藏了数值的承诺空间中高效验证这些承诺和它们之间复杂代数关系（尤其是乘法关系）的桥梁。正是这些工具的精妙组合，才使得 zk-SNARKs 能够实现其神奇的零知识、简洁和非交互特性。\n4.3 证明的诞生与检验\n结合了 QAP 的转换和上述核心加密工具后，一个 zk-SNARK 证明的生成和验证过程（以 Groth16 这类基于 QAP 和配对的方案为例）大致如下：\n前提：可信设置\n在任何证明生成或验证之前，系统需要进行一次可信设置。这次设置会生成一套公共参数 (CRS)，其中包括证明密钥 (Proving Key, PK) 和验证密钥 (Verification Key, VK)。PK 将交给证明者，VK 将交给验证者。这些密钥中编码了与特定 QAP 相关的多项式（如 Ak(x),Bk(x),Ck(x),Z(x)A_k(x), B_k(x), C_k(x), Z(x)Ak​(x),Bk​(x),Ck​(x),Z(x)）在秘密点 τ\\tauτ (以及可能的其他秘密点，如 α,β\\alpha, \\betaα,β) 上的“隐藏”信息（通常是椭圆曲线点）。\n证明者 (Prover) 的工作：\n当证明者想要证明她知道某个计算的有效见证 sss 时，她会执行以下步骤：\n\n计算见证与 QAP 系数： 对于给定的公开输入，证明者使用她的秘密输入计算出完整的见证向量 sss。然后，她使用这个 sss 和 QAP 的定义（即多项式 Ak(x),Bk(x),Ck(x)A_k(x), B_k(x), C_k(x)Ak​(x),Bk​(x),Ck​(x)）来确定满足 P(x)=H(x)Z(x)P(x) = H(x)Z(x)P(x)=H(x)Z(x) 的多项式 P(x)P(x)P(x) 和 H(x)H(x)H(x) 的系数。\n对多项式进行“加密”求值和承诺： 证明者使用证明密钥 (PK) 和她的见证 sss。PK 中包含了可信设置中生成的秘密值 τ\\tauτ (以及可能的 α,β\\alpha, \\betaα,β 等) 的加密幂次（例如 gτi,gατi,gβτig^{\\tau^i}, g^{\\alpha \\tau^i}, g^{\\beta \\tau^i}gτi,gατi,gβτi 等椭圆曲线点）。证明者利用这些加密值和同态隐藏的特性，计算出对 P(τ),H(τ)P(\\tau), H(\\tau)P(τ),H(τ) 以及其他相关多项式在这些秘密点上求值的承诺。这些承诺本身也是椭圆曲线点，它们隐藏了 τ\\tauτ 的值以及 P(x)P(x)P(x) 和 H(x)H(x)H(x) 的具体系数（从而隐藏了见证 sss）。\n生成证明 π\\piπ： 证明 π\\piπ 通常由一组椭圆曲线点组成。这些点是根据 QAP 方程、证明者的见证以及可信设置参数精心构造的，它们共同编码了对 QAP 等式成立的论证。例如，在 Groth16 中，证明可能包含对 L(τ),R(τ),O(τ)L(\\tau), R(\\tau), O(\\tau)L(τ),R(τ),O(τ)（或其线性组合）的承诺，以及一个用于验证 H(τ)H(\\tau)H(τ) 正确性的承诺。\n\n验证者 (Verifier) 的工作：\n当验证者收到证明者发送的证明 π\\piπ（以及相应的公开输入）后，她会执行以下步骤：\n\n使用验证密钥 (VK)： 验证密钥 (VK) 中也包含了可信设置中生成的与 QAP 和秘密点相关的一些“摘要”信息（同样是椭圆曲线点）。\n执行配对检查： 验证者使用证明 π\\piπ 中的点、公开输入以及验证密钥 (VK) 中的点，执行少量预定义的椭圆曲线配对运算，并检查这些运算的结果是否满足一个或多个特定的等式。这些配对等式被设计用来间接验证原始的 QAP 方程 P(τ)=H(τ)Z(τ)P(\\tau) = H(\\tau)Z(\\tau)P(τ)=H(τ)Z(τ) 是否成立，以及证明者提供的承诺是否与公开输入一致，并且是否正确地使用了见证。\n接受或拒绝： 如果所有的配对检查都通过，验证者就接受这个证明，相信证明者确实知道一个有效的见证，使得原始计算成立。否则，拒绝该证明。\n\n整个过程虽然数学上极为复杂，但对验证者而言，交互却异常简单：接收一个非常小的证明 π\\piπ，然后执行一次快速的计算来验证它。这种证明者付出巨大计算代价（生成证明可能很慢）而验证者只需付出微小代价（验证证明非常快）的不对称性，是 SNARKs 的一个显著特征，也是其适用于需要大量验证者的场景（如区块链）的关键原因。\n","categories":["学习笔记"],"tags":["Crypto","ZK-SNARKs","Elliptic Curve"]},{"title":"LLM Quick Look","url":"/2025/09/23/LLM-Quick-Look/","content":"Speech And Language Processing ch7笔记\n\n1. 核心理论：将语言建模为概率分布\n大型语言模型（LLM）的根本目标是构建一个精确的、可计算的通用语言概率分布模型。它不仅仅是预测下一个词，而是试图理解和复现人类语言中蕴含的无穷的语法、语义、语用和世界知识。\n1.1. 数学基石：概率链式法则\n语言模型的核心是概率链式法则（Chain Rule of Probability）。它将一个复杂序列的联合概率 P(w1,w2,...,wm)P(w_1, w_2, ..., w_m)P(w1​,w2​,...,wm​) 分解为一系列在计算上可行的、局部的条件概率的乘积。\nP(W)=∏i=1mP(wi∣w&lt;i)P(W) = \\prod_{i=1}^{m} P(w_i | w_{&lt;i})\nP(W)=i=1∏m​P(wi​∣w&lt;i​)\n这个分解是革命性的，因为它将一个无法直接建模的、高维度的联合分布问题，转化为了一个序列化的预测任务。LLM的本质就是一个强大的函数近似器，通过深度神经网络学习来精确地计算 P(wi∣w&lt;i)P(w_i | w_{&lt;i})P(wi​∣w&lt;i​)。\n1.2. 自回归生成：一个计算性的反馈循环\n自回归（Autoregressive）生成是一个动态过程，其中模型的输出在下一步会成为其输入的一部分。\n\n信息流：Context_t -&gt; Model -&gt; P(w | Context_t) -&gt; Sample(w_t) -&gt; Context_&#123;t+1&#125; = Context_t + w_t\n计算视角：这个过程可以看作是在一个巨大的、由所有可能文本构成的图（Graph of Language）中进行路径搜索。每一步采样都是在当前节点选择一条通往下一个节点的边，而模型的概率分布则是选择每条边的权重。不同的采样策略（贪心、Top-p等）相当于不同的路径搜索启发式算法。\n\n\n2. 核心架构：Transformer的深度剖析\n现代LLM的性能飞跃归功于Transformer架构，其核心是自注意力机制（Self-Attention）。\n2.1. 解码器架构（Decoder-only）- GPT系列\n这是当前生成式LLM的主流。其关键在于带掩码的多头自注意力（Masked Multi-Head Self-Attention）。\n\n工作流详解：\n\n输入嵌入：输入序列的每个token被转换为一个高维向量（Embedding）。\n位置编码：由于注意力机制本身不感知顺序，一个位置向量被加到每个token的嵌入上，以注入序列的位置信息。\nTransformer块（重复N次）：\na. 掩码自注意力：对于序列中的每个token，它会计算一个“注意力分数”，来决定对序列中包括自身在内的所有先前token的关注程度。这里的掩码是一个上三角矩阵，其值为负无穷大。在Softmax操作后，未来token的注意力分数会变为0，从而确保模型在预测位置 t 时，无法“看到” t+1, t+2, … 的信息。这就是**因果性（Causality）**的实现。\nb. 残差连接 &amp; 层归一化 (Add &amp; Norm)：将自注意力的输出与其输入相加（残差连接），然后进行层归一化。这有助于缓解梯度消失问题，稳定并加速训练。\nc. 前馈神经网络 (FFN)：一个简单的两层全连接网络，对每个位置的表示进行非线性变换，增加模型的表示能力。\nd. 再次 Add &amp; Norm。\n输出：最后一个Transformer块的输出经过一个线性层和Softmax函数，映射到整个词汇表的概率分布上。\n\n\n\n2.2. 编码器架构（Encoder-only）- BERT系列\n编码器的核心是双向自注意力，它旨在生成深度上下文感知的词表示（Embeddings）。\n\n训练目标 - 掩码语言模型 (MLM)：\n\n输入: The quick [MASK] fox jumps over the [MASK] dog.\n目标: 预测 [MASK] 处的词是 brown 和 lazy。\n意义: 为了正确预测 brown，模型必须同时理解 quick 和 fox。这种双向依赖性迫使模型学习深度的语境关系，使其生成的词嵌入非常适合下游的**自然语言理解（NLU）**任务。\n\n\n\n2.3. 编码器-解码器架构 - T5, BART\n这种架构通过**交叉注意力（Cross-Attention）**机制将两部分连接起来。\n\n交叉注意力详解：在解码器的每个Transformer块中，除了掩码自注意力层外，还有一个交叉注意力层。\n\nQuery (Q): 来自解码器自身的、代表当前生成状态的向量。\nKey (K) &amp; Value (V): 来自编码器处理完整个输入序列后的最终输出向量。\n过程: 解码器在生成每个新词时，都会用它的Query去“查询”编码器输出的所有信息（Keys），并根据相关性（注意力分数）提取最相关的信息（Values）。这允许解码器在生成的每一步都能“回顾”输入序列的全部内容，对于翻译和摘要等任务至关重要。\n\n\n\n\n3. 高级交互：提示工程的内在机理\n3.1. 上下文学习（In-context Learning）的本质\nICL并非传统意义上的学习（即权重更新），而是一种推理时（Inference-time）的模式匹配和元学习（Meta-learning）。\n\n注意力视角：当模型处理一个包含少样本示例的提示时，其注意力机制会将新问题与示例问题进行模式匹配。示例中的“输入-输出”格式和逻辑关系，会引导模型在处理新问题时激活相似的神经元通路和计算模式。\n元学习视角：可以认为，LLM在海量的预训练数据中，已经见过了无数种“任务”的文本描述（例如，维基百科中的问答对、代码网站的函数和文档、翻译网站的平行语料）。ICL正是利用了模型在预训练阶段学到的这种“学习如何学习”的元能力。提示中的示例，为模型选择和应用哪种已有的“技能”提供了强有力的线索。\n\n3.2. 思维链（Chain-of-Thought, CoT）的认知科学解释\nCoT的成功可以类比于人类的系统2思维（System 2 Thinking）。\n\n系统1 vs. 系统2：\n\n系统1（直觉）: 快速、自动、不费力的思考。标准提示下的LLM回答类似于系统1，直接给出一个直觉性的答案。\n系统2（推理）: 缓慢、有条理、需要耗费精力的逻辑推理。\n\n\nCoT的作用：CoT提示强制模型进入“系统2”模式。通过要求模型输出中间推理步骤，它将一个复杂的、多步的推理任务分解成了一系列简单的、单步的预测任务。这不仅为模型提供了“认知草稿纸”，也使得每一步的计算都更加聚焦和准确，从而显著降低了最终答案出错的概率。\n进阶技术 - 自我一致性（Self-Consistency）：这是CoT的增强版。让模型使用CoT生成多个不同的推理路径，然后对最终答案进行“投票”。如果多个不同的推理过程都指向同一个答案，那么这个答案正确的可能性就大大增加了。\n\n\n4. 核心算法：采样策略的概率论与权衡\n4.1. 温度（Temperature）与分布熵\n温度τ直接影响模型输出概率分布的熵（Entropy），熵是衡量系统不确定性或随机性的度量。\n\n低 τ (&lt; 1): 降低了分布的熵。模型对其最高概率的预测变得“过度自信”，输出更具确定性，但也更保守、缺乏创造力。\n高 τ (&gt; 1): 增加了分布的熵。模型变得“不那么自信”，愿意考虑更多可能性，输出更具多样性和随机性，但也有可能产生更多不相关的胡言乱语。\n\n4.2. Top-p (Nucleus) 采样的优势\nTop-p采样因其动态适应性而被广泛认为是优于Top-k的策略。\n\n场景对比:\n\n上下文: The capital of France is [MASK].\n\n模型预测: 概率分布非常尖锐 (low entropy)。Paris 的概率可能高达99%。\nTop-p (p=0.95): 候选核（nucleus）可能只包含 &#123;&quot;Paris&quot;&#125;。\nTop-k (k=50): 仍然会保留50个候选词，其中49个是极低概率的噪声。\n\n\n上下文: I went to the store and bought a [MASK].\n\n模型预测: 概率分布非常平坦 (high entropy)。gallon, carton, bunch, bottle 等词的概率可能都很接近。\nTop-p (p=0.95): 候选核会自动扩大，包含所有这些合理的选项。\nTop-k (k=3): 可能会过早地截断，漏掉一些同样合理的选项。\n\n\n\n\n\n4.3. 束搜索（Beam Search）的计算细节\nBeam Search在每一步都保留b个最可能的候选序列（hypotheses）。\n\n对数概率: 在实践中，为了避免浮点数下溢（多个小于1的概率相乘会变得极小）和提高计算效率，所有计算都在对数空间完成。序列的概率等于其各部分对数概率之和：log⁡P(w1,...,wt)=∑i=1tlog⁡P(wi∣w&lt;i)\\log P(w_1, ..., w_t) = \\sum_{i=1}^{t} \\log P(w_i | w_{&lt;i})\nlogP(w1​,...,wt​)=i=1∑t​logP(wi​∣w&lt;i​)\n\n主要缺陷 - 生成重复和无趣的文本: Beam Search倾向于选择局部最优的高概率词。在开放式生成中，这常常导致模型陷入重复循环（如 “I think I think I think…”）或选择最“安全”、最平庸的词汇，因为这些词在训练语料中统计上最常见。\n\n\n5. 训练LLM：从统计学习到行为对齐\n5.1. 预训练：构建语言的基础模型\n这是一个巨大的表征学习（Representation Learning）过程。模型不仅在学习语言，还在其参数中隐式地编码了海量关于世界的事实、常识和推理模式。这就是为什么它们被称为基础模型（Foundation Models）。\n5.2. SFT：行为克隆与格式遵循\nSFT的本质是行为克隆（Behavior Cloning）。它教会模型如何模仿“有用助手”的对话格式。例如，学习如何回答问题而不是续写问题，如何遵循指令，以及如何使用Markdown、代码块等格式。它塑造了模型的外在行为模式。\n5.3. 对齐：塑造模型的内在价值观\n对齐解决的是SFT无法解决的深层问题：什么是“好”的回答？“好”是模糊的，取决于上下文、安全性和人类偏好。\n\n\nRLHF的精髓：\n\n学习人类偏好: 奖励模型（RM）是RLHF的核心。它将模糊的、不可直接优化的“人类偏好”转化为了一个可计算的、可优化的奖励信号。\n在策略空间中搜索: 原始的LLM定义了一个巨大的策略空间（即所有可能的回答方式）。强化学习算法（如PPO）则是在这个空间中进行探索（Exploration），寻找能够最大化奖励信号（即最符合人类偏好）的策略。\nPPO的作用: **近端策略优化（Proximal Policy Optimization, PPO）**在RLHF中至关重要。它通过一个KL散度惩罚项，确保更新后的模型（策略）不会与原始SFT模型偏离太远。这既能防止模型为了追求高奖励而“胡言乱语”（奖励黑客, Reward Hacking），也能防止模型忘记在预训练和SFT阶段学到的语言能力（灾难性遗忘, Catastrophic Forgetting）。\n\n\n\n前沿技术 - 直接偏好优化 (DPO) &amp; Constitutional AI:\n\nDPO: 一种更简单、更稳定的对齐方法，它绕过了训练奖励模型这一步，直接使用偏好数据（哪个回答更好）来微调LLM。\nConstitutional AI (Anthropic): 一种减少对人类标注依赖的对齐方法。模型被要求遵循一个明确的“宪法”（一系列原则，如“选择最无害的回答”）。模型首先自我批判和修正其回答以符合宪法，然后基于这些修正后的回答来微调自己。\n\n\n\n\n6. 评估LLM：超越单一指标的整体视图\n6.1. 评估哲学：内在 vs. 外在\n\n内在评估（Intrinsic Evaluation）: 衡量模型自身的语言能力，不关心具体任务。困惑度是典型的内在评估。\n外在评估（Extrinsic Evaluation）: 衡量模型在特定下游任务上的表现。所有基准测试（MMLU, HumanEval等）都是外在评估。\n一个现代的、全面的LLM评估体系必须两者兼顾。\n\n6.2. 基准测试的挑战与未来\n\n饱和与过拟合: 许多知名基准测试（如SQuAD）已经“饱和”，即模型的表现已经超过了人类平均水平。这引发了对模型是否真正“理解”还是仅仅“过拟合”了测试集模式的担忧。\n动态与对抗性评估: 未来的评估趋势是动态和对抗性的。例如，HELM (Holistic Evaluation of Language Models) 试图在一个涵盖数十种任务和指标的、标准化的框架下评估模型。Dynabench平台则允许人类与模型持续互动，动态地寻找模型会犯错的新案例，并将其加入评估集，从而创建一个不断演进、永不饱和的基准。\n\n\n7. 伦理与安全：技术与责任的交汇点\n7.1. 幻觉的根源与RAG的机制\n\n根源: 幻觉是模型**参数化知识（Parametric Knowledge）**的固有缺陷。模型试图将其在训练数据中见过的无数事实压缩并存储在其有限的参数中。这个过程是有损的，当需要回忆或组合这些知识时，就容易出错。\nRAG的原理 - 从参数化知识到来源知识: RAG通过引入**非参数化知识（Non-parametric Knowledge）**来解决这个问题。\n\n检索器（Retriever）: 这是一个信息检索系统。它将用户问题编码为一个向量，然后在知识库（也被编码为向量）中进行高效的相似性搜索，找出最相关的文本片段。\n生成器（Generator）: 即LLM。它接收原始问题和检索到的文本片段作为增强的上下文，然后基于这些有来源依据的信息来生成答案。\nRAG将模型的角色从一个“无所不知的专家”转变为一个“聪明的图书管理员”，它知道去哪里查找信息，并能很好地总结和呈现。\n\n\n\n7.2. 偏见与对齐的深层挑战\n对齐不仅仅是技术问题，也是**价值规范（Normative）**问题。为模型定义“无害”、“有用”等标准时，我们实际上是在将特定文化、特定人群的价值观编码到AI系统中。这引发了深刻的哲学问题：谁来决定这些价值观？如何确保其公平性和普适性？Constitutional AI正是对这一挑战的一种技术回应，试图使这个价值注入过程更加透明和可控。\n","categories":["学习笔记"],"tags":["大语言模型","LLM","简介"]}]